{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from data import *\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "vocales = [\"a.wav\", \"e.wav\", \"i.wav\", \"o.wav\", \"u.wav\"]\n",
    "consonantes = [\"f.wav\", \"j.wav\", \"s.wav\", \"sh.wav\"]\n",
    "audios = []\n",
    "recortados = []\n",
    "colores1 = [\"#03045E\", \"#0077B6\", \"#00B4D8\", \"#90E0EF\", \"#CAF0F8\"]\n",
    "colores2 = [\"#BFB5AF\", \"#ECE2D0\", \"#D5B9B2\", \"#A26769\", \"#582C4D\"]\n",
    "colores3 = [\"#CAA8F5\", \"#9984D4\", \"#592E83\", \"#230C33\"]\n",
    "\n",
    "\n",
    "frec = 14700\n",
    "N = int(0.2 * frec)  # 200 ms\n",
    "\n",
    "def guardar_señal(señal):\n",
    "    audio, _ = sf.read(señal)\n",
    "    audios.append(audio)\n",
    "    audio_recortado = audio[:N]\n",
    "    recortados.append(audio_recortado)\n",
    "\n",
    "\n",
    "    \n",
    "for vocal in vocales:\n",
    "    guardar_señal(vocal)\n",
    "for consonante in consonantes:\n",
    "    guardar_señal(consonante)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_señal(audio_recortado, color, nombre):\n",
    "    tiempo = np.arange(0, N) / frec\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(tiempo, audio_recortado, color=color)\n",
    "    plt.title(f\"señal de {nombre}\")\n",
    "    plt.xlabel('Tiempo (segundos)')\n",
    "    plt.ylabel('Amplitud')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "colores1 = colores1[::-1]\n",
    "for i, vocal in enumerate(vocales):\n",
    "    graficar_señal(recortados[i], colores1[i], vocal)\n",
    "\n",
    "colores3 = colores3[::-1]\n",
    "for i, consonante in enumerate(consonantes):\n",
    "    graficar_señal(recortados[i + len(vocales)], colores3[i], consonante)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "autocorrelaciones = []\n",
    "lags_var = []\n",
    "\n",
    "def calcular_autocorrelacion(audio_recortado):\n",
    "    n = len(audio_recortado)\n",
    "\n",
    "    autocorr = signal.correlate(audio_recortado, audio_recortado, mode='full')\n",
    "\n",
    "\n",
    "    autocorrelaciones.append(autocorr)\n",
    "    lags = np.arange(-len(audio_recortado)+1, len(audio_recortado))\n",
    "    lags_var.append(lags)\n",
    "\n",
    "for audio_recortado in recortados:\n",
    "    calcular_autocorrelacion(audio_recortado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_autocorrelacion(autocorr, color, nombre, lags):\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(lags, autocorr, color=color)\n",
    "    plt.title(f\"Autocorrelación de {nombre}\")\n",
    "    plt.xlabel('Lags)')\n",
    "    plt.ylabel('Amplitud')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "for i, vocal in enumerate(vocales):\n",
    "    graficar_autocorrelacion(autocorrelaciones[i], colores1[i], vocal, lags_var[i])\n",
    "for i, consonante in enumerate(consonantes):\n",
    "    graficar_autocorrelacion(autocorrelaciones[i + len(vocales)], colores3[i], consonante, lags_var[i + len(vocales)])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
